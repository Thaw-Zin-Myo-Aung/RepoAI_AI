# RepoAI â€“ AI Service Overview

RepoAI is the intelligent core of the refactoring assistant.  It receives user prompts and repository access data from the backend, orchestrates specialized AI agents and returns validated, refactored code with supporting evidence:contentReference[oaicite:0]{index=0}.

> **ğŸ“ Workspace Structure:** See [WORKSPACE_STRUCTURE.md](./WORKSPACE_STRUCTURE.md) for the full directory layout and code organization.

## How It Works

### 1ï¸âƒ£ Request Intake
The backend (Spring Boot) sends a POST request to the AI service containing:
- **User prompt** â€“ the requested refactor or analysis  
- **GitHub credentials** â€“ repository access token and metadata  
- **Optional scope** â€“ specific file paths, branch, or constraints  

A session is initialized and an orchestrated agent workflow begins:contentReference[oaicite:1]{index=1}.

### 2ï¸âƒ£ Agentic Workflow
RepoAI uses modular agents that can be tested or replaced independently.  The core pipeline is:

| Agent                | Role                     | Highlights |
|----------------------|--------------------------|-----------|
| **Intake Agent**     | Prompt parsing           | Interprets the user prompt and produces a structured `JobSpec` describing the intended changes:contentReference[oaicite:2]{index=2}. |
| **Planner Agent**    | Plan generation          | Generates a detailed `RefactorPlan`, assigning risk levels to each step and estimating durations based on repository context:contentReference[oaicite:3]{index=3}.  Plans include mitigation strategies for highâ€‘risk steps. |
| **Transformer Agent**| Code refactoring         | Applies code changes using deterministic codemods and largeâ€‘language models.  Supports both batch mode and streaming mode, yielding fileâ€‘byâ€‘file updates for realâ€‘time feedback:contentReference[oaicite:4]{index=4}. |
| **Validator Agent**  | Quality assurance        | Compiles the project, runs unit tests and performs static analysis (code quality, Spring conventions, security, test coverage):contentReference[oaicite:5]{index=5}.  It returns a `ValidationResult` with pass/fail, confidence and coverage metrics. |
| **PR Narrator Agent**| Documentation            | Summarizes the changes and validation outcomes into a humanâ€‘readable pullâ€‘request description for reviewers. |
| **Policy Gate**      | Safety check             | Verifies branch protection, change size and nonâ€‘destructive operations before pushing changes. |

### ğŸ§® Orchestration and Error Recovery
A central `OrchestratorAgent` coordinates the pipeline.  It manages session state, riskâ€‘aware decision making and retries.  If validation fails, it consults an LLM with **Retry Strategy Instructions** to decide whether to retry, modify the plan or abort:contentReference[oaicite:6]{index=6}.  A backup of modified files is created before transformation, enabling rollback on critical errors:contentReference[oaicite:7]{index=7}.

### ğŸ’¬ Interactive Mode
Use `ChatOrchestrator` for humanâ€‘inâ€‘theâ€‘loop refactoring.  It extends the base orchestrator to request user confirmations at key points, such as plan approval, applying changes and handling validation failures:contentReference[oaicite:8]{index=8}.  Users can modify the plan or abort via chat messages.

### ğŸ“¶ Streaming & Progress Updates
Enable streaming mode to receive realâ€‘time updates as each file is generated.  The orchestrator sends `PipelineUpdateMessage` events over SSE or WebSocket connections containing stage, progress and humanâ€‘readable messages:contentReference[oaicite:9]{index=9}.  Progress milestones are mapped across the stages: intake (0â€‘15%), planning (15â€‘30%), transformation (30â€‘55%), validation (55â€‘75%), narration (75â€‘85%) and completion (100%):contentReference[oaicite:10]{index=10}.

### ğŸ§© Model Routing (Gemini)
RepoAI dynamically selects largeâ€‘language models per agent role through a **Model Router**.  Each role has ordered fallbacks that can be overridden through environment variables:contentReference[oaicite:11]{index=11}.

| Role             | Default Gemini Models â†’ Fallbacks             | Purpose |
|------------------|-----------------------------------------------|---------|
| **INTAKE**       | `gemini-2.5-flash` â†’ `gemini-2.0-flash-exp` â†’ `gemini-2.0-flash` | Fast prompt parsing |
| **PLANNER**      | `gemini-2.5-pro` â†’ `gemini-2.5-flash` â†’ `gemini-2.0-flash` | Deep reasoning & JSON plan generation |
| **CODER**        | `gemini-2.5-pro` â†’ `gemini-2.5-flash` â†’ `gemini-2.0-flash` | Code generation and transformation |
| **PR_NARRATOR**  | `gemini-2.5-flash` â†’ `gemini-2.0-flash` â†’ `gemini-2.5-flash-lite` | Summarization and PR narration |
| **EMBEDDING**    | `text-embedding-004` | Lightweight RAG embeddings |

### âš™ï¸ Configuration via Environment Variables
You can override default models by setting commaâ€‘separated lists in `.env`:

```bash
GOOGLE_API_KEY=your_API_key_here

MODEL_ROUTE_INTAKE="gemini-2.5-flash,gemini-2.0-flash-exp,gemini-2.0-flash"
MODEL_ROUTE_PLANNER="gemini-2.5-pro,gemini-2.5-flash,gemini-2.0-flash"
MODEL_ROUTE_CODER="gemini-2.5-pro,gemini-2.5-flash,gemini-2.0-flash"
MODEL_ROUTE_PR="gemini-2.5-flash,gemini-2.0-flash,gemini-2.5-flash-lite"
EMBEDDING_MODEL="text-embedding-004"

GEMINI_DEFAULT_TIMEOUT_S=60
GEMINI_MAX_RETRIES=2
