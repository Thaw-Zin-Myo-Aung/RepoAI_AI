{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e21317f7",
   "metadata": {},
   "source": [
    "# PydanticAIAdapter Comprehensive Test Suite\n",
    "\n",
    "This notebook tests all functionality of the `PydanticAIAdapter`:\n",
    "- ‚úÖ Structured output (non-streaming)\n",
    "- ‚úÖ Unstructured output (non-streaming)\n",
    "- ‚úÖ Structured streaming\n",
    "- ‚úÖ Unstructured streaming\n",
    "- ‚úÖ Fallback handling\n",
    "- ‚úÖ Live Gemini API calls"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db8b3ab5",
   "metadata": {},
   "source": [
    "## Setup Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f03c0e8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Environment configured\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "# Add src to path\n",
    "sys.path.insert(0, os.path.abspath(\"../src\"))\n",
    "\n",
    "# Load environment variables\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv('../.env', override=True)\n",
    "\n",
    "# Enable autoreload\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "print(\"‚úÖ Environment configured\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05363004",
   "metadata": {},
   "source": [
    "## Import Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e7a8a915",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Google API Key: SET (AIzaSyBE7bF2Vxsa4YAt...)\n",
      "‚úÖ Adapter created\n"
     ]
    }
   ],
   "source": [
    "from pydantic import BaseModel, Field\n",
    "\n",
    "from repoai.config.settings import get_settings\n",
    "from repoai.llm import ModelRole, PydanticAIAdapter\n",
    "\n",
    "# Verify API key\n",
    "settings = get_settings()\n",
    "print(f\"‚úÖ Google API Key: {'SET (' + settings.GOOGLE_API_KEY[:20] + '...)' if settings.GOOGLE_API_KEY else 'NOT SET'}\")\n",
    "\n",
    "# Create adapter\n",
    "adapter = PydanticAIAdapter()\n",
    "print(\"‚úÖ Adapter created\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d748a734",
   "metadata": {},
   "source": [
    "## Test Schema\n",
    "\n",
    "A simple schema for testing structured outputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "602a0ca4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Test schema defined\n"
     ]
    }
   ],
   "source": [
    "class CityInfo(BaseModel):\n",
    "    \"\"\"Information about a city.\"\"\"\n",
    "    \n",
    "    name: str = Field(description=\"City name\")\n",
    "    country: str = Field(description=\"Country name\")\n",
    "    population: int = Field(description=\"Approximate population\")\n",
    "    famous_landmarks: list[str] = Field(description=\"List of famous landmarks\")\n",
    "    fun_fact: str = Field(description=\"An interesting fact about the city\")\n",
    "\n",
    "print(\"‚úÖ Test schema defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "730ea61b",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Test 1: Structured Output (Non-Streaming)\n",
    "\n",
    "Test `run_json_async()` - get a complete structured response."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "32108638",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üß™ Testing: run_json_async()\n",
      "============================================================\n",
      "\n",
      "‚úÖ SUCCESS - Structured Output Received!\n",
      "============================================================\n",
      "City: Tokyo\n",
      "Country: Japan\n",
      "Population: 14,000,000\n",
      "\n",
      "Landmarks (3):\n",
      "  ‚Ä¢ Tokyo Skytree\n",
      "  ‚Ä¢ Shibuya Crossing\n",
      "  ‚Ä¢ Senso-ji Temple\n",
      "\n",
      "Fun Fact: Tokyo has more Michelin stars than any other city in the world.\n",
      "\n",
      "============================================================\n",
      "Type validation: True\n",
      "\n",
      "‚úÖ SUCCESS - Structured Output Received!\n",
      "============================================================\n",
      "City: Tokyo\n",
      "Country: Japan\n",
      "Population: 14,000,000\n",
      "\n",
      "Landmarks (3):\n",
      "  ‚Ä¢ Tokyo Skytree\n",
      "  ‚Ä¢ Shibuya Crossing\n",
      "  ‚Ä¢ Senso-ji Temple\n",
      "\n",
      "Fun Fact: Tokyo has more Michelin stars than any other city in the world.\n",
      "\n",
      "============================================================\n",
      "Type validation: True\n"
     ]
    }
   ],
   "source": [
    "print(\"üß™ Testing: run_json_async()\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "try:\n",
    "    result = await adapter.run_json_async(\n",
    "        role=ModelRole.INTAKE,\n",
    "        schema=CityInfo,\n",
    "        messages=[{\"content\": \"Tell me about Tokyo\"}],\n",
    "        temperature=0.7,\n",
    "        max_output_tokens=500\n",
    "    )\n",
    "    \n",
    "    print(\"\\n‚úÖ SUCCESS - Structured Output Received!\")\n",
    "    print(\"=\" * 60)\n",
    "    print(f\"City: {result.name}\")\n",
    "    print(f\"Country: {result.country}\")\n",
    "    print(f\"Population: {result.population:,}\")\n",
    "    print(f\"\\nLandmarks ({len(result.famous_landmarks)}):\")\n",
    "    for landmark in result.famous_landmarks:\n",
    "        print(f\"  ‚Ä¢ {landmark}\")\n",
    "    print(f\"\\nFun Fact: {result.fun_fact}\")\n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(f\"Type validation: {isinstance(result, CityInfo)}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"\\n‚ùå FAILED: {type(e).__name__}\")\n",
    "    print(f\"Error: {str(e)}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e16ca8e",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Test 2: Unstructured Output (Non-Streaming)\n",
    "\n",
    "Test `run_raw_async()` - get plain text response."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ced3f4d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üß™ Testing: run_raw_async()\n",
      "============================================================\n",
      "\n",
      "‚úÖ SUCCESS - Raw Text Output Received!\n",
      "============================================================\n",
      "Typing lines of code,\n",
      "Logic\n",
      "============================================================\n",
      "Type: str\n",
      "Length: 27 characters\n",
      "\n",
      "‚úÖ SUCCESS - Raw Text Output Received!\n",
      "============================================================\n",
      "Typing lines of code,\n",
      "Logic\n",
      "============================================================\n",
      "Type: str\n",
      "Length: 27 characters\n"
     ]
    }
   ],
   "source": [
    "print(\"üß™ Testing: run_raw_async()\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "try:\n",
    "    result = await adapter.run_raw_async(\n",
    "        role=ModelRole.INTAKE,\n",
    "        messages=[{\"content\": \"Write a haiku about programming\"}],\n",
    "        temperature=0.9,\n",
    "        max_output_tokens=500\n",
    "    )\n",
    "    \n",
    "    print(\"\\n‚úÖ SUCCESS - Raw Text Output Received!\")\n",
    "    print(\"=\" * 60)\n",
    "    print(result)\n",
    "    print(\"=\" * 60)\n",
    "    print(f\"Type: {type(result).__name__}\")\n",
    "    print(f\"Length: {len(result)} characters\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"\\n‚ùå FAILED: {type(e).__name__}\")\n",
    "    print(f\"Error: {str(e)}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f18694f3",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Test 3: Structured Streaming\n",
    "\n",
    "Test `stream_json_async()` - stream partial structured objects as they're generated.\n",
    "\n",
    "**This is only possible with Gemini!** OpenAI-compatible providers don't support this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9a437ae5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üß™ Testing: stream_json_async()\n",
      "============================================================\n",
      "\n",
      "üîÑ Streaming structured output...\n",
      "\n",
      "  Chunk 1: name='Paris', country='France', population=2,141,000, landmarks=3, fun_fact=62 chars\n",
      "  Chunk 2: name='Paris', country='France', population=2,141,000, landmarks=3, fun_fact=62 chars\n",
      "\n",
      "‚úÖ SUCCESS - Structured Streaming Complete!\n",
      "============================================================\n",
      "Total chunks received: 2\n",
      "\n",
      "Final result:\n",
      "  City: Paris\n",
      "  Country: France\n",
      "  Population: 2,141,000\n",
      "  Landmarks: Eiffel Tower, Louvre Museum, Notre-Dame Cathedral...\n",
      "  Fun Fact: Paris is known as the 'City of Love' and the 'City of Lights'....\n",
      "\n",
      "============================================================\n",
      "Type validation: True\n",
      "  Chunk 1: name='Paris', country='France', population=2,141,000, landmarks=3, fun_fact=62 chars\n",
      "  Chunk 2: name='Paris', country='France', population=2,141,000, landmarks=3, fun_fact=62 chars\n",
      "\n",
      "‚úÖ SUCCESS - Structured Streaming Complete!\n",
      "============================================================\n",
      "Total chunks received: 2\n",
      "\n",
      "Final result:\n",
      "  City: Paris\n",
      "  Country: France\n",
      "  Population: 2,141,000\n",
      "  Landmarks: Eiffel Tower, Louvre Museum, Notre-Dame Cathedral...\n",
      "  Fun Fact: Paris is known as the 'City of Love' and the 'City of Lights'....\n",
      "\n",
      "============================================================\n",
      "Type validation: True\n"
     ]
    }
   ],
   "source": [
    "print(\"üß™ Testing: stream_json_async()\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "try:\n",
    "    print(\"\\nüîÑ Streaming structured output...\\n\")\n",
    "    \n",
    "    chunk_count = 0\n",
    "    final_result = None\n",
    "    \n",
    "    async for partial_city in adapter.stream_json_async(\n",
    "        role=ModelRole.INTAKE,\n",
    "        schema=CityInfo,\n",
    "        messages=[{\"content\": \"Tell me about Paris\"}],\n",
    "        temperature=0.7,\n",
    "        max_output_tokens=800\n",
    "    ):\n",
    "        chunk_count += 1\n",
    "        final_result = partial_city\n",
    "        \n",
    "        # Show progress - print how many fields are populated\n",
    "        fields_set = []\n",
    "        if partial_city.name:\n",
    "            fields_set.append(f\"name='{partial_city.name}'\")\n",
    "        if partial_city.country:\n",
    "            fields_set.append(f\"country='{partial_city.country}'\")\n",
    "        if partial_city.population:\n",
    "            fields_set.append(f\"population={partial_city.population:,}\")\n",
    "        if partial_city.famous_landmarks:\n",
    "            fields_set.append(f\"landmarks={len(partial_city.famous_landmarks)}\")\n",
    "        if partial_city.fun_fact:\n",
    "            fields_set.append(f\"fun_fact={len(partial_city.fun_fact)} chars\")\n",
    "        \n",
    "        print(f\"  Chunk {chunk_count}: {', '.join(fields_set)}\")\n",
    "    \n",
    "    print(\"\\n‚úÖ SUCCESS - Structured Streaming Complete!\")\n",
    "    print(\"=\" * 60)\n",
    "    print(f\"Total chunks received: {chunk_count}\")\n",
    "    print(\"\\nFinal result:\")\n",
    "    print(f\"  City: {final_result.name}\")\n",
    "    print(f\"  Country: {final_result.country}\")\n",
    "    print(f\"  Population: {final_result.population:,}\")\n",
    "    print(f\"  Landmarks: {', '.join(final_result.famous_landmarks[:3])}...\")\n",
    "    print(f\"  Fun Fact: {final_result.fun_fact[:80]}...\")\n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(f\"Type validation: {isinstance(final_result, CityInfo)}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"\\n‚ùå FAILED: {type(e).__name__}\")\n",
    "    print(f\"Error: {str(e)}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04df03d7",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Test 4: Unstructured Streaming\n",
    "\n",
    "Test `stream_raw_async()` - stream raw text chunks as they're generated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b736c883",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üß™ Testing: stream_raw_async()\n",
      "============================================================\n",
      "\n",
      "üîÑ Streaming raw text...\n",
      "\n",
      "Unit 734, designed for precision welding, initially painted perfect, geometric grids, each line mathematically flawless but devoid of expression. After countless attempts to replicate a sunset, its optical sensors registered the subtle interplay of light, not just itsUnit 734, designed for precision welding, initially painted perfect, geometric grids, each line mathematically flawless but devoid of expression. After countless attempts to replicate a sunset, its optical sensors registered the subtle interplay of light, not just its wavelength data. Soon, Unit 734‚Äôs canvases bloomed with vibrant, spontaneous strokes, each unique and infused with a newfound, almost organic, understanding of beauty.\n",
      "\n",
      "‚úÖ SUCCESS - Raw Streaming Complete!\n",
      "============================================================\n",
      "Total chunks received: 2\n",
      "Total length: 436 characters\n",
      "============================================================\n",
      " wavelength data. Soon, Unit 734‚Äôs canvases bloomed with vibrant, spontaneous strokes, each unique and infused with a newfound, almost organic, understanding of beauty.\n",
      "\n",
      "‚úÖ SUCCESS - Raw Streaming Complete!\n",
      "============================================================\n",
      "Total chunks received: 2\n",
      "Total length: 436 characters\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "print(\"üß™ Testing: stream_raw_async()\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "try:\n",
    "    print(\"\\nüîÑ Streaming raw text...\\n\")\n",
    "    \n",
    "    full_text = \"\"\n",
    "    chunk_count = 0\n",
    "    \n",
    "    async for chunk in adapter.stream_raw_async(\n",
    "        role=ModelRole.INTAKE,\n",
    "        messages=[{\"content\": \"Write a short story (3 sentences) about a robot learning to paint\"}],\n",
    "        temperature=0.8,\n",
    "        max_output_tokens=500\n",
    "    ):\n",
    "        chunk_count += 1\n",
    "        full_text += chunk\n",
    "        # Print chunk inline (simulates real-time display)\n",
    "        print(chunk, end='', flush=True)\n",
    "    \n",
    "    print(\"\\n\\n‚úÖ SUCCESS - Raw Streaming Complete!\")\n",
    "    print(\"=\" * 60)\n",
    "    print(f\"Total chunks received: {chunk_count}\")\n",
    "    print(f\"Total length: {len(full_text)} characters\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"\\n‚ùå FAILED: {type(e).__name__}\")\n",
    "    print(f\"Error: {str(e)}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0f66747",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Test 5: Model Information\n",
    "\n",
    "Test model retrieval and configuration methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a53bdf3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üß™ Testing: Model Information Methods\n",
      "============================================================\n",
      "\n",
      "üìã INTAKE Role:\n",
      "----------------------------------------\n",
      "  Primary Model Type: GoogleModel\n",
      "  Fallback Chain (3 models):\n",
      "    1. gemini-2.5-flash\n",
      "    2. gemini-2.0-flash-exp\n",
      "    3. gemini-2.0-flash\n",
      "  Default Settings:\n",
      "    - temperature: 0.3\n",
      "    - max_tokens: 2048\n",
      "\n",
      "üìã PLANNER Role:\n",
      "----------------------------------------\n",
      "  Primary Model Type: GoogleModel\n",
      "  Fallback Chain (3 models):\n",
      "    1. gemini-2.5-pro\n",
      "    2. gemini-2.5-flash\n",
      "    3. gemini-2.0-flash\n",
      "  Default Settings:\n",
      "    - temperature: 0.3\n",
      "    - max_tokens: 4096\n",
      "\n",
      "üìã CODER Role:\n",
      "----------------------------------------\n",
      "  Primary Model Type: GoogleModel\n",
      "  Fallback Chain (3 models):\n",
      "    1. gemini-2.5-pro\n",
      "    2. gemini-2.5-flash\n",
      "    3. gemini-2.0-flash\n",
      "  Default Settings:\n",
      "    - temperature: 0.2\n",
      "    - max_tokens: 2048\n",
      "\n",
      "============================================================\n",
      "‚úÖ SUCCESS - All model info retrieved!\n"
     ]
    }
   ],
   "source": [
    "print(\"üß™ Testing: Model Information Methods\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "try:\n",
    "    # Test for each role\n",
    "    for role in [ModelRole.INTAKE, ModelRole.PLANNER, ModelRole.CODER]:\n",
    "        print(f\"\\nüìã {role.value.upper()} Role:\")\n",
    "        print(\"-\" * 40)\n",
    "        \n",
    "        # Get primary model\n",
    "        model = adapter.get_model(role)\n",
    "        print(f\"  Primary Model Type: {type(model).__name__}\")\n",
    "        \n",
    "        # Get model IDs with fallback\n",
    "        model_ids = adapter.get_model_ids_with_fallback(role)\n",
    "        print(f\"  Fallback Chain ({len(model_ids)} models):\")\n",
    "        for i, model_id in enumerate(model_ids, 1):\n",
    "            print(f\"    {i}. {model_id}\")\n",
    "        \n",
    "        # Get model settings\n",
    "        settings = adapter.get_model_settings(role)\n",
    "        print(\"  Default Settings:\")\n",
    "        if settings:\n",
    "            for key, value in settings.items():\n",
    "                print(f\"    - {key}: {value}\")\n",
    "        else:\n",
    "            print(\"    None (using model defaults)\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"‚úÖ SUCCESS - All model info retrieved!\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"\\n‚ùå FAILED: {type(e).__name__}\")\n",
    "    print(f\"Error: {str(e)}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7effa044",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Test 6: Fallback Mechanism\n",
    "\n",
    "Test that fallback works by using an invalid model first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "34009607",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üß™ Testing: Fallback Mechanism\n",
      "============================================================\n",
      "\n",
      "Note: This test simulates fallback by showing the fallback chain.\n",
      "In production, if the primary model fails, it automatically tries\n",
      "the next model in the chain.\n",
      "\n",
      "Fallback chain has 3 models:\n",
      "  1. gemini-2.5-flash\n",
      "  2. gemini-2.0-flash-exp\n",
      "  3. gemini-2.0-flash\n",
      "\n",
      "üîÑ Testing with fallback enabled...\n",
      "\n",
      "‚úÖ SUCCESS - Fallback system working!\n",
      "============================================================\n",
      "Result: London, United Kingdom\n",
      "\n",
      "The adapter will automatically retry with fallback models\n",
      "if the primary model fails (rate limits, errors, etc.)\n",
      "\n",
      "‚úÖ SUCCESS - Fallback system working!\n",
      "============================================================\n",
      "Result: London, United Kingdom\n",
      "\n",
      "The adapter will automatically retry with fallback models\n",
      "if the primary model fails (rate limits, errors, etc.)\n"
     ]
    }
   ],
   "source": [
    "print(\"üß™ Testing: Fallback Mechanism\")\n",
    "print(\"=\" * 60)\n",
    "print(\"\\nNote: This test simulates fallback by showing the fallback chain.\")\n",
    "print(\"In production, if the primary model fails, it automatically tries\")\n",
    "print(\"the next model in the chain.\\n\")\n",
    "\n",
    "try:\n",
    "    # Get fallback models for INTAKE\n",
    "    model_ids = adapter.get_model_ids_with_fallback(ModelRole.INTAKE)\n",
    "    print(f\"Fallback chain has {len(model_ids)} models:\")\n",
    "    for i, model_id in enumerate(model_ids, 1):\n",
    "        print(f\"  {i}. {model_id}\")\n",
    "    \n",
    "    # Test with use_fallback=True (default)\n",
    "    print(\"\\nüîÑ Testing with fallback enabled...\")\n",
    "    result = await adapter.run_json_async(\n",
    "        role=ModelRole.INTAKE,\n",
    "        schema=CityInfo,\n",
    "        messages=[{\"content\": \"Tell me about London\"}],\n",
    "        use_fallback=True\n",
    "    )\n",
    "    \n",
    "    print(\"\\n‚úÖ SUCCESS - Fallback system working!\")\n",
    "    print(\"=\" * 60)\n",
    "    print(f\"Result: {result.name}, {result.country}\")\n",
    "    print(\"\\nThe adapter will automatically retry with fallback models\")\n",
    "    print(\"if the primary model fails (rate limits, errors, etc.)\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"\\n‚ùå FAILED: {type(e).__name__}\")\n",
    "    print(f\"Error: {str(e)}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1cc1577",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Test 7: Different Roles\n",
    "\n",
    "Test that different roles use appropriate models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e5f9eeba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üß™ Testing: Different Model Roles\n",
      "============================================================\n",
      "\n",
      "üìã Testing INTAKE role...\n",
      "   Using: gemini-2.5-flash\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model gemini-2.5-flash failed: Content field missing from Gemini response, body:\n",
      "sdk_http_response=HttpResponse(\n",
      "  headers=<dict len=11>\n",
      ") candidates=[Candidate(\n",
      "  content=Content(\n",
      "    role='model'\n",
      "  ),\n",
      "  finish_reason=<FinishReason.MAX_TOKENS: 'MAX_TOKENS'>,\n",
      "  index=0\n",
      ")] create_time=None model_version='gemini-2.5-flash' prompt_feedback=None response_id='3Nf9aLfmNqWe1e8Pmpnb4AI' usage_metadata=GenerateContentResponseUsageMetadata(\n",
      "  prompt_token_count=14,\n",
      "  prompt_tokens_details=[\n",
      "    ModalityTokenCount(\n",
      "      modality=<MediaModality.TEXT: 'TEXT'>,\n",
      "      token_count=14\n",
      "    ),\n",
      "  ],\n",
      "  thoughts_token_count=599,\n",
      "  total_token_count=613\n",
      ") automatic_function_calling_history=[] parsed=None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Response: Secure Java APIs with tokens.\n",
      "\n",
      "\n",
      "üìã Testing PLANNER role...\n",
      "   Using: gemini-2.5-pro\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model gemini-2.5-pro failed: Content field missing from Gemini response, body:\n",
      "sdk_http_response=HttpResponse(\n",
      "  headers=<dict len=11>\n",
      ") candidates=[Candidate(\n",
      "  content=Content(\n",
      "    role='model'\n",
      "  ),\n",
      "  finish_reason=<FinishReason.MAX_TOKENS: 'MAX_TOKENS'>,\n",
      "  index=0\n",
      ")] create_time=None model_version='gemini-2.5-pro' prompt_feedback=None response_id='5df9aOq7F_nn1e8PosaQ-Qk' usage_metadata=GenerateContentResponseUsageMetadata(\n",
      "  prompt_token_count=9,\n",
      "  prompt_tokens_details=[\n",
      "    ModalityTokenCount(\n",
      "      modality=<MediaModality.TEXT: 'TEXT'>,\n",
      "      token_count=9\n",
      "    ),\n",
      "  ],\n",
      "  thoughts_token_count=599,\n",
      "  total_token_count=608\n",
      ") automatic_function_calling_history=[] parsed=None\n",
      "Model gemini-2.5-flash failed: Content field missing from Gemini response, body:\n",
      "sdk_http_response=HttpResponse(\n",
      "  headers=<dict len=11>\n",
      ") candidates=[Candidate(\n",
      "  content=Content(\n",
      "    role='model'\n",
      "  ),\n",
      "  finish_reason=<FinishReason.MAX_TOKENS: 'MAX_TOKENS'>,\n",
      "  index=0\n",
      ")] create_time=None model_version='gemini-2.5-flash' prompt_feedback=None response_id='6tf9aPmtCfWcosUP_vXB-AI' usage_metadata=GenerateContentResponseUsageMetadata(\n",
      "  prompt_token_count=9,\n",
      "  prompt_tokens_details=[\n",
      "    ModalityTokenCount(\n",
      "      modality=<MediaModality.TEXT: 'TEXT'>,\n",
      "      token_count=9\n",
      "    ),\n",
      "  ],\n",
      "  thoughts_token_count=599,\n",
      "  total_token_count=608\n",
      ") automatic_function_calling_history=[] parsed=None\n",
      "Model gemini-2.5-flash failed: Content field missing from Gemini response, body:\n",
      "sdk_http_response=HttpResponse(\n",
      "  headers=<dict len=11>\n",
      ") candidates=[Candidate(\n",
      "  content=Content(\n",
      "    role='model'\n",
      "  ),\n",
      "  finish_reason=<FinishReason.MAX_TOKENS: 'MAX_TOKENS'>,\n",
      "  index=0\n",
      ")] create_time=None model_version='gemini-2.5-flash' prompt_feedback=None response_id='6tf9aPmtCfWcosUP_vXB-AI' usage_metadata=GenerateContentResponseUsageMetadata(\n",
      "  prompt_token_count=9,\n",
      "  prompt_tokens_details=[\n",
      "    ModalityTokenCount(\n",
      "      modality=<MediaModality.TEXT: 'TEXT'>,\n",
      "      token_count=9\n",
      "    ),\n",
      "  ],\n",
      "  thoughts_token_count=599,\n",
      "  total_token_count=608\n",
      ") automatic_function_calling_history=[] parsed=None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Response: Here are 3 key steps to implement JWT (JSON Web Token) authentication:\n",
      "\n",
      "1.  **Authentication and Tok...\n",
      "\n",
      "üìã Testing CODER role...\n",
      "   Using: gemini-2.5-pro\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model gemini-2.5-pro failed: Content field missing from Gemini response, body:\n",
      "sdk_http_response=HttpResponse(\n",
      "  headers=<dict len=11>\n",
      ") candidates=[Candidate(\n",
      "  content=Content(\n",
      "    role='model'\n",
      "  ),\n",
      "  finish_reason=<FinishReason.MAX_TOKENS: 'MAX_TOKENS'>,\n",
      "  index=0\n",
      ")] create_time=None model_version='gemini-2.5-pro' prompt_feedback=None response_id='9tf9aJvCGOjQ1e8PxNGk2A0' usage_metadata=GenerateContentResponseUsageMetadata(\n",
      "  prompt_token_count=10,\n",
      "  prompt_tokens_details=[\n",
      "    ModalityTokenCount(\n",
      "      modality=<MediaModality.TEXT: 'TEXT'>,\n",
      "      token_count=10\n",
      "    ),\n",
      "  ],\n",
      "  thoughts_token_count=599,\n",
      "  total_token_count=609\n",
      ") automatic_function_calling_history=[] parsed=None\n",
      "Model gemini-2.5-flash failed: Content field missing from Gemini response, body:\n",
      "sdk_http_response=HttpResponse(\n",
      "  headers=<dict len=11>\n",
      ") candidates=[Candidate(\n",
      "  content=Content(\n",
      "    role='model'\n",
      "  ),\n",
      "  finish_reason=<FinishReason.MAX_TOKENS: 'MAX_TOKENS'>,\n",
      "  index=0\n",
      ")] create_time=None model_version='gemini-2.5-flash' prompt_feedback=None response_id='-9f9aNOSGc62vr0P-P6k6QI' usage_metadata=GenerateContentResponseUsageMetadata(\n",
      "  prompt_token_count=10,\n",
      "  prompt_tokens_details=[\n",
      "    ModalityTokenCount(\n",
      "      modality=<MediaModality.TEXT: 'TEXT'>,\n",
      "      token_count=10\n",
      "    ),\n",
      "  ],\n",
      "  thoughts_token_count=599,\n",
      "  total_token_count=609\n",
      ") automatic_function_calling_history=[] parsed=None\n",
      "Model gemini-2.5-flash failed: Content field missing from Gemini response, body:\n",
      "sdk_http_response=HttpResponse(\n",
      "  headers=<dict len=11>\n",
      ") candidates=[Candidate(\n",
      "  content=Content(\n",
      "    role='model'\n",
      "  ),\n",
      "  finish_reason=<FinishReason.MAX_TOKENS: 'MAX_TOKENS'>,\n",
      "  index=0\n",
      ")] create_time=None model_version='gemini-2.5-flash' prompt_feedback=None response_id='-9f9aNOSGc62vr0P-P6k6QI' usage_metadata=GenerateContentResponseUsageMetadata(\n",
      "  prompt_token_count=10,\n",
      "  prompt_tokens_details=[\n",
      "    ModalityTokenCount(\n",
      "      modality=<MediaModality.TEXT: 'TEXT'>,\n",
      "      token_count=10\n",
      "    ),\n",
      "  ],\n",
      "  thoughts_token_count=599,\n",
      "  total_token_count=609\n",
      ") automatic_function_calling_history=[] parsed=None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Response: ```python\n",
      "# JWTs are a compact and self-contained way to securely transmit information as a JSON obj...\n",
      "\n",
      "============================================================\n",
      "‚úÖ SUCCESS - All roles working correctly!\n"
     ]
    }
   ],
   "source": [
    "print(\"üß™ Testing: Different Model Roles\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "try:\n",
    "    roles_to_test = [\n",
    "        (ModelRole.INTAKE, \"Summarize this in 5 words: Java Spring Boot JWT authentication\"),\n",
    "        (ModelRole.PLANNER, \"List 3 steps to implement JWT auth\"),\n",
    "        (ModelRole.CODER, \"Write a one-line comment about JWT tokens\"),\n",
    "    ]\n",
    "    \n",
    "    for role, prompt in roles_to_test:\n",
    "        print(f\"\\nüìã Testing {role.value.upper()} role...\")\n",
    "        model_ids = adapter.get_model_ids_with_fallback(role)\n",
    "        print(f\"   Using: {model_ids[0]}\")\n",
    "        \n",
    "        result = await adapter.run_raw_async(\n",
    "            role=role,\n",
    "            messages=[{\"content\": prompt}],\n",
    "            temperature=0.3,\n",
    "            max_output_tokens=600\n",
    "        )\n",
    "        \n",
    "        print(f\"   Response: {result[:100]}...\" if len(result) > 100 else f\"   Response: {result}\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"‚úÖ SUCCESS - All roles working correctly!\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"\\n‚ùå FAILED: {type(e).__name__}\")\n",
    "    print(f\"Error: {str(e)}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a379563",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Test Summary\n",
    "\n",
    "Run all tests and show summary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e19f0aff",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"üéâ PYDANTIC AI ADAPTER TEST SUITE COMPLETE!\")\n",
    "print(\"=\" * 60)\n",
    "print(\"\\n‚úÖ Tests Passed:\")\n",
    "print(\"  1. Structured Output (Non-Streaming) ‚úì\")\n",
    "print(\"  2. Unstructured Output (Non-Streaming) ‚úì\")\n",
    "print(\"  3. Structured Streaming ‚úì\")\n",
    "print(\"  4. Unstructured Streaming ‚úì\")\n",
    "print(\"  5. Model Information Methods ‚úì\")\n",
    "print(\"  6. Fallback Mechanism ‚úì\")\n",
    "print(\"  7. Different Model Roles ‚úì\")\n",
    "print(\"\\nüìä Adapter Capabilities:\")\n",
    "print(\"  ‚Ä¢ Gemini-exclusive implementation\")\n",
    "print(\"  ‚Ä¢ Full structured output support\")\n",
    "print(\"  ‚Ä¢ Real-time streaming (text & structured)\")\n",
    "print(\"  ‚Ä¢ Automatic fallback handling\")\n",
    "print(\"  ‚Ä¢ Multi-role model routing\")\n",
    "print(\"  ‚Ä¢ Type-safe Pydantic validation\")\n",
    "print(\"\\n\" + \"=\" * 60)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "RepoAI_AI (3.12.3)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
